{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvz_lyuAO3Qu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as functional\n",
        "#print(torch.cuda.is_available())\n",
        "from tqdm import tqdm\n",
        "#Author: Monynich Kiem\n",
        "#Date: 04/2022\n",
        "#Purpose: Tiny Shakespeare - Use an RNN to output text generation with Shakespeare as the training devide\n",
        "#Main reference: Dr. Harrison's code as given to us in lecture\n",
        "#other references:\n",
        "#https://www.kaggle.com/code/sumantindurkhya/text-generation-from-shakespeare-s-play-pytorch/notebook\n",
        "#https://www.youtube.com/watch?v=xs6dOWlpQbM\n",
        "#https://opendatascience.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler/\n",
        "\n",
        "#hyperparamters\n",
        "epochs = 69\n",
        "batch = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#read and split vocab------------------------------------------------------------------------------\n",
        "#read in\n",
        "file = open(\"tiny-shakespeare.txt\", \"r\").read()\n",
        "#extract characters\n",
        "characters = list(set(file))\n",
        "#vocab section\n",
        "intChar = dict(enumerate(characters))\n",
        "charInt = {character: index for index, character in intChar.items()}\n",
        "#print(intChar)\n",
        "vocab_size = len(charInt)\n",
        "\n",
        "#functions--------------------------------------------------------------------------------\n",
        "def create_one_hot(sequence, vocab_size):\n",
        "    #defines a matrix of vocab_size with all 0's so use np.zeros\n",
        "    #dim = batch size x seq lenth x vocab size\n",
        "    encoding = np.zeros((1, len(sequence), vocab_size), dtype=np.float32)\n",
        "    for i in range(len(sequence)):\n",
        "        encoding[0, i, sequence[i]] = 1\n",
        "    return encoding\n",
        "\n",
        "#rnn class\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    #Define how inputs translate into outputs\n",
        "    def forward(self, x):\n",
        "        #hidden_state = self.init_hidden()\n",
        "        output, hidden_state = self.rnn(x)\n",
        "        #take off one to deal with extra dim from batch\n",
        "        output = output.contiguous().view(-1, self.hidden_size)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden_state\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "        return hidden\n",
        "\n",
        "#split into segments that can be used\n",
        "#aka chunking up the text\n",
        "#https://stackoverflow.com/questions/434287/what-is-the-most-pythonic-way-to-iterate-over-a-list-in-chunks\n",
        "def chunker(seq, size):\n",
        "    return [seq[pos:pos + size] for pos, i in enumerate(list(seq)) if pos % size == 0]\n",
        "\n",
        "def get_loss_and_train(model):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    return loss, optimizer\n",
        "\n",
        "#implementation----------------------------------------------------------------------------\n",
        "model = RNNModel(vocab_size, vocab_size, 420, 1) \n",
        "lossANDtrain = get_loss_and_train(model)\n",
        "\n",
        "#define loss and optimizer\n",
        "loss = lossANDtrain[0]\n",
        "optimizer = lossANDtrain[1]\n",
        "\n",
        "#initialize variables\n",
        "input_sequence = []\n",
        "target_sequence = []\n",
        "sentences = []\n",
        "\n",
        "segments = chunker(file, 69)\n",
        "#creating small sections of text, similar to what was shown in class with the first page of harry potter and the philosopher's stone\n",
        "new_segment = \"\"\n",
        "for i in range(len(segments)):\n",
        "    new_segment += segments[i]\n",
        "    if i % 3 == 2:\n",
        "        sentences.append(new_segment)\n",
        "        new_segment = \"\"\n",
        "        \n",
        "#shifting sequences by 1, similar to the pseudocode where First became irst so it can predict the next one\n",
        "for i in range(len(sentences)):\n",
        "    input_sequence.append(sentences[i][:-1])\n",
        "    target_sequence.append(sentences[i][1:])\n",
        "    \n",
        "#constructing the one hots, replace all chars with ints\n",
        "for i in range(len(sentences)):\n",
        "    input_sequence[i] = [charInt[character] for character in input_sequence[i]]\n",
        "    target_sequence[i] = [charInt[character] for character in target_sequence[i]]\n",
        "    #converting target_seq into a tensor, for loss only need the int output\n",
        "\n",
        "#input sequences into one-hots\n",
        "for i in range(len(input_sequence)):\n",
        "    input_sequence[i] = create_one_hot(input_sequence[i], vocab_size)\n",
        "\n",
        "input_tensor = torch.FloatTensor(input_sequence)\n",
        "input_tensor = torch.reshape(input_tensor, (len(input_tensor), len(sentences[0])-1, vocab_size))\n",
        "\n",
        "#https://opendatascience.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler/\n",
        "training = TensorDataset(input_tensor, torch.FloatTensor(target_sequence))\n",
        "trainLoader = DataLoader(training, batch_size=batch)\n",
        "#print(type(trainLoader))\n",
        "\n",
        "#convert everything to use the gpu\n",
        "model.cuda()\n",
        "#https://www.geeksforgeeks.org/progress-bars-in-python/\n",
        "#decided to use progress bars to see how long it took \n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nEpoch\", epoch+1)\n",
        "    for x, y in tqdm(trainLoader):\n",
        "        #https://stackoverflow.com/questions/58095627/how-to-fix-input-and-hidden-tensors-are-not-at-the-same-device-in-pytorch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        #print(type(x))\n",
        "        #y = y.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = model(x)\n",
        "        lossValue = loss(output, y.view(-1).long())\n",
        "        lossValue.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Loss: {:.4f}\".format(lossValue.item()))\n",
        "\n",
        "print(\"\\nComplete:\")\n",
        "print(\"Final Loss: {:.4f}\".format(lossValue.item()))\n",
        "\n",
        "def predict(model, character):\n",
        "    character_input = np.array([charInt[c] for c in character])\n",
        "    character_input = create_one_hot(character_input, vocab_size)\n",
        "    character_input = torch.from_numpy(character_input).to(device)\n",
        "    out, hidden = model(character_input)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    character_index = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return intChar[character_index], hidden\n",
        "    \n",
        "def sample(model, out_len, start='ROMEO:'):\n",
        "    characters = [ch for ch in start]\n",
        "    current_size = out_len - len(characters)\n",
        "    for i in range(current_size):\n",
        "        character, hidden_state = predict(model, characters)\n",
        "        characters.append(character)\n",
        "\n",
        "    return ''.join(characters)\n",
        "\n",
        "print(sample(model, 100)) #needs to make the input from prediction definition cuda in order to print out or else there is an error\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hwk4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}